{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/soe/jafidler/.cache/huggingface/datasets/squad/plain_text/1.0.0/4fffa6cf76083860f85fa83486ec3028e7e32c342c218ff2a620fc6b2868483a)\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import json\n",
    "\n",
    "import datasets\n",
    "squad_dataset = datasets.load_dataset('squad')\n",
    "from datasets import concatenate_datasets\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "covid_file = '../data/COVID-QA.json'\n",
    "bio_file = '../bioASQ/bioASQ.json'\n",
    "\n",
    "def get_data_from_json(filename):\n",
    "    jsonfile = open(covid_file, 'r')\n",
    "    data = jsonfile.read()\n",
    "    jsonfile.close()\n",
    "    return json.loads(data)\n",
    "\n",
    "covid_data = get_data_from_json(covid_file)\n",
    "bio_data = get_data_from_json(bio_file)\n",
    "\n",
    "#datasets.set_caching_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def make_and_save_full_dataset(covid=None, squad = None, bioASQ = None, path = '../data/squad_bioASQ_covidQA/'):\n",
    "    squad = datasets.Dataset.from_dict(squad_qa[:])\n",
    "    bioASQ = datasets.Dataset.from_dict(bioASQ[:])\n",
    "    if covid is not None:\n",
    "        full_data = datasets.dataset_dict.DatasetDict({'squad':squad, 'covid':covid,  'bio':bioASQ})\n",
    "    else:\n",
    "        full_data = datasets.dataset_dict.DatasetDict({'squad':squad,'bio':bioASQ})\n",
    "\n",
    "    full_data.save_to_disk(path)\n",
    "\n",
    "def get_dataset(filename):\n",
    "    return datasets.load_dataset('custom_squad.py', data_files= {'train':filename})['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-1d18a620853d8414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset squad/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /soe/jafidler/.cache/huggingface/datasets/squad/default-1d18a620853d8414/0.0.0/cb00e306c4924563ce3d1292a1ce1b86b2753dab6285ce43c87b39c5bda3ef4e...\n",
      "LOADING DATAFILES\n",
      "{'train': '../data/COVID-QA.json'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d542499662c4218861792b86683cc72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-d665e54172161a2c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset squad downloaded and prepared to /soe/jafidler/.cache/huggingface/datasets/squad/default-1d18a620853d8414/0.0.0/cb00e306c4924563ce3d1292a1ce1b86b2753dab6285ce43c87b39c5bda3ef4e. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset squad/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /soe/jafidler/.cache/huggingface/datasets/squad/default-d665e54172161a2c/0.0.0/cb00e306c4924563ce3d1292a1ce1b86b2753dab6285ce43c87b39c5bda3ef4e...\n",
      "LOADING DATAFILES\n",
      "{'train': '../bioASQ/bioASQ.json'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4ecbd843924faa8a8a108bc7ce36e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset squad downloaded and prepared to /soe/jafidler/.cache/huggingface/datasets/squad/default-d665e54172161a2c/0.0.0/cb00e306c4924563ce3d1292a1ce1b86b2753dab6285ce43c87b39c5bda3ef4e. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "covid_qa = get_dataset(covid_file)\n",
    "bio_qa = get_dataset(bio_file)\n",
    "squad_qa = concatenate_datasets([squad_dataset['train'], squad_dataset['validation']])\n",
    "\n",
    "covid_bio_squad_dataset_path = \"../data/squad_bioASQ_covidQA/\"\n",
    "\n",
    "#this is just for testing purposes, I am going to make both of these files very small only at max 3000 datasets\n",
    "# squad_qa = datasets.Dataset.from_dict(squad_qa[:50])\n",
    "# bio_qa = datasets.Dataset.from_dict(bio_qa[:20])\n",
    "# covid_qa = datasets.Dataset.from_dict(covid_qa[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "make_and_save_full_dataset(squad=squad_qa,bioASQ=bio_qa,path=covid_bio_squad_dataset_path)\n",
    "\n",
    "K = 8\n",
    "to_remove_per_step = int(squad_qa.num_rows / K)\n",
    "bio_remove_per_step = int(bio_qa.num_rows / K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_gradual_ft(output_dir, checkpoint, k_fold):\n",
    "    !CUDA_VISIBLE_DEVICES=2 python run_qa.py \\\n",
    "      --model_name_or_path {checkpoint} \\\n",
    "      --dataset_name ../data/squad_bioASQ_covidQA/\\\n",
    "      --do_train \\\n",
    "      --do_eval \\\n",
    "      --do_predict \\\n",
    "      --per_device_train_batch_size 32\\\n",
    "      --per_device_eval_batch_size 32\\\n",
    "      --evaluation_strategy \"no\" \\\n",
    "      --save_strategy \"no\" \\\n",
    "      --logging_strategy \"epoch\" \\\n",
    "      --learning_rate 8e-6 \\\n",
    "      --num_train_epochs 1 \\\n",
    "      --max_seq_length 384 \\\n",
    "      --doc_stride 128 \\\n",
    "      --k_fold_cross_valid {k_fold} \\\n",
    "      --output_dir {output_dir} \\\n",
    "      --overwrite_output_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "k_fold = 5\n",
    "directory = '../models/gradual_ft_baseline2/'\n",
    "output_dir = '../models/gradual_ft_baseline2/Split-' + str(k_fold)+'/'\n",
    "\n",
    "squad_total_len = squad_qa.num_rows\n",
    "bio_total_len = bio_qa.num_rows\n",
    "import sys\n",
    "log_file = open('log_file.txt','w')\n",
    "sys.stdout = log_file\n",
    "\n",
    "for i in range(K):\n",
    "    print('\\n\\n**************************************************')\n",
    "    print('==================================================')\n",
    "    print('          At Gradual Fine Tuning Step: ',i+1)\n",
    "    print('**************************************************')\n",
    "    print('==================================================\\n\\n')\n",
    "    if i < 1:\n",
    "        run_gradual_ft(directory,'roberta-base', k_fold )\n",
    "    else:\n",
    "        run_gradual_ft(directory, output_dir, k_fold)\n",
    "        squad_qa.shuffle()\n",
    "        bio_qa.shuffle()\n",
    "        covid_qa = datasets.Dataset.from_dict(covid_qa[:])\n",
    "\n",
    "    if i < 4: #remove from squad\n",
    "        if to_remove_per_step > squad_qa.num_rows:\n",
    "            print('not enough data')\n",
    "            break\n",
    "        print(f'\\n========== Removing {to_remove_per_step} from SQuAD ({squad_qa.num_rows}/{squad_total_len})==========')\n",
    "        squad_qa = datasets.Dataset.from_dict(squad_qa[:-to_remove_per_step])\n",
    "        bio_temp = datasets.Dataset.from_dict(bio_qa[:1])\n",
    "        make_and_save_full_dataset(squad=squad_qa, bioASQ=bio_temp, path=covid_bio_squad_dataset_path)\n",
    "    else: #remove from bioASQ\n",
    "        if to_remove_per_step > bio_qa.num_rows:\n",
    "            print('not enough data')\n",
    "            break\n",
    "        print(f'\\n========= Removing {bio_remove_per_step} from BioASQ ({bio_qa.num_rows}/{bio_total_len}) =========')\n",
    "        bio_qa = datasets.Dataset.from_dict(bio_qa[:-bio_remove_per_step])\n",
    "        squad_temp = datasets.Dataset.from_dict(squad_qa[:1])\n",
    "        make_and_save_full_dataset(squad=squad_temp, bioASQ=bio_qa,path=covid_bio_squad_dataset_path)\n",
    "\n",
    "print('Finished process')\n",
    "sys.stdout = sys.__stdout__\n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
