{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/soe/jafidler/.cache/huggingface/datasets/squad/plain_text/1.0.0/4fffa6cf76083860f85fa83486ec3028e7e32c342c218ff2a620fc6b2868483a)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import transformers\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import datasets\n",
    "squad_dataset = datasets.load_dataset('squad')\n",
    "from datasets import concatenate_datasets, load_dataset\n",
    "\n",
    "covid_file = '../data/COVID-QA.json'\n",
    "bio_file = '../bioASQ/bioASQ.json'\n",
    "\n",
    "def make_and_save_full_dataset(train, valid, test, path):\n",
    "    full_data = datasets.dataset_dict.DatasetDict({'train':train, 'validation':valid, 'test': test})\n",
    "    full_data.save_to_disk(path)\n",
    "\n",
    "def get_dataset(filename):\n",
    "    return datasets.load_dataset('custom_squad.py', data_files= {'train':filename})['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import run_qa\n",
    "\n",
    "def run_gradual_ft(output_dir, checkpoint, covid_val):\n",
    "    !python run_qa.py \\\n",
    "      --model_name_or_path {checkpoint} \\\n",
    "      --dataset_name ../data/full_squad_covidQA/ \\\n",
    "      --do_train \\\n",
    "      --do_eval \\\n",
    "      --do_predict \\\n",
    "      --per_device_train_batch_size 32\\\n",
    "      --per_device_eval_batch_size 32\\\n",
    "      --evaluation_strategy \"no\" \\\n",
    "      --save_strategy \"no\" \\\n",
    "      --logging_strategy \"epoch\" \\\n",
    "      --learning_rate 1e-5 \\\n",
    "      --num_train_epochs 1 \\\n",
    "      --max_seq_length 384 \\\n",
    "      --doc_stride 128 \\\n",
    "      --output_dir {output_dir} \\\n",
    "      --overwrite_output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-1d18a620853d8414\n",
      "Reusing dataset squad (/soe/jafidler/.cache/huggingface/datasets/squad/default-1d18a620853d8414/0.0.0/cb00e306c4924563ce3d1292a1ce1b86b2753dab6285ce43c87b39c5bda3ef4e)\n",
      "Using custom data configuration default-d665e54172161a2c\n",
      "Reusing dataset squad (/soe/jafidler/.cache/huggingface/datasets/squad/default-d665e54172161a2c/0.0.0/cb00e306c4924563ce3d1292a1ce1b86b2753dab6285ce43c87b39c5bda3ef4e)\n"
     ]
    }
   ],
   "source": [
    "data_files = {}\n",
    "data_files[\"train\"] = covid_file\n",
    "\n",
    "covid_qa = get_dataset(covid_file)\n",
    "bio_qa = get_dataset(bio_file)\n",
    "\n",
    "squad_qa = concatenate_datasets([squad_dataset['train'], squad_dataset['validation']])\n",
    "covid_and_squad_dataset_path = \"../data/full_squad_covidQA\"\n",
    "\n",
    "# squad_qa = datasets.Dataset.from_dict(squad_qa[:50])\n",
    "# covid_qa = datasets.Dataset.from_dict(covid_qa[:20])\n",
    "# bio_qa = datasets.Dataset.from_dict(bio_qa[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "k_fold = 5\n",
    "K = 6\n",
    "\n",
    "for i in range(k_fold):\n",
    "    covid_fold = covid_qa.shard(k_fold, i)\n",
    "\n",
    "    covid_test = covid_fold.shard(2, 0)\n",
    "    covid_val = covid_fold.shard(2, 1)\n",
    "    covid_train = concatenate_datasets([covid_qa.shard(k_fold, j) for j in range(k_fold) if j != i])\n",
    "\n",
    "    #make_and_save_full_dataset(covid_train, squad_qa, covid_val, covid_test, covid_and_squad_dataset_path)\n",
    "\n",
    "    checkpoint = 'roberta-base'\n",
    "    cur_dir = '../models/gradual_ft_baseline_lr1e-5/split_' + str(i)\n",
    "\n",
    "    log_file = open(cur_dir + \"/log_file.txt\",\"w+\")\n",
    "\n",
    "    sys.stdout = log_file\n",
    "\n",
    "    squad_qa.shuffle()\n",
    "    bio_qa.shuffle()\n",
    "\n",
    "    num_of_shards = int(K/2)\n",
    "    squad_qa_shards = [squad_qa.shard(num_of_shards,i) for i in range(num_of_shards)]\n",
    "    bio_qa_shards = [bio_qa.shard(num_of_shards,i) for i in range(num_of_shards)]\n",
    "\n",
    "    squad_qa_cur = concatenate_datasets(squad_qa_shards)\n",
    "    bio_qa_cur = concatenate_datasets(bio_qa_shards)\n",
    "    \n",
    "    squad_rows_to_remove = len(squad_qa_shards[0])\n",
    "    bio_rows_to_remove = len(bio_qa_shards[0])\n",
    "    L = squad_qa_shards + bio_qa_shards + [covid_train]\n",
    "    print(f'Gradual finetuning with K={K} ({K//2} per SQuAD and bioASQ)')\n",
    "    for n in range(K+1):\n",
    "        output_dir = cur_dir + '/checkpoint_' + str(n)\n",
    "\n",
    "       \n",
    "        full_dataset = concatenate_datasets(L)\n",
    "        make_and_save_full_dataset(full_dataset, covid_val, covid_test, covid_and_squad_dataset_path)\n",
    "\n",
    "        print(f'n={n} =============')\n",
    "        print('Total: ',full_dataset.num_rows)\n",
    "        \n",
    "        run_gradual_ft(output_dir, checkpoint, covid_val)\n",
    "        print('=================\\n')\n",
    "       \n",
    "        checkpoint = output_dir\n",
    "    \n",
    "        if n < K//2:\n",
    "            print(f'Removing {squad_rows_to_remove} from SQuAD')\n",
    "            _ = L.pop(0)\n",
    "            \n",
    "        elif n < K:\n",
    "            print(f'Removing {bio_rows_to_remove} from bioASQ')\n",
    "            _ = L.pop(0)\n",
    "\n",
    "        else:\n",
    "            assert full_dataset.num_rows == covid_train.num_rows\n",
    "            full_dataset = covid_train\n",
    "    \n",
    "    log_file.close()\n",
    "sys.stdout = sys.__stdout__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
